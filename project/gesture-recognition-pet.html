<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/_next/static/media/29a6e977ce941007-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="/_next/static/media/575bcb56b500cc9b-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="/_next/static/media/a5c349ac2ad38ba2-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" as="image" href="/icons/logo/Unity.png"/><link rel="stylesheet" href="/_next/static/css/5e26cd74581c4c3d.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-004d1fe77d25eedc.js"/><script src="/_next/static/chunks/4bd1b696-b83f0c1b0dc5f4df.js" async=""></script><script src="/_next/static/chunks/517-a156340ae23239b9.js" async=""></script><script src="/_next/static/chunks/main-app-e51e5795d713e0fb.js" async=""></script><script src="/_next/static/chunks/565-826789f130585a74.js" async=""></script><script src="/_next/static/chunks/295-0f87b6b3c04a55eb.js" async=""></script><script src="/_next/static/chunks/app/layout-1d05ed19c4855c67.js" async=""></script><script src="/_next/static/chunks/app/project/gesture-recognition-pet/page-82abab72787272c6.js" async=""></script><link rel="preload" href="https://www.googletagmanager.com/gtag/js?id=G-7GRVFVX2JL" as="script"/><meta name="next-size-adjust" content=""/><title>Mei Yu Chi | UI/UX Designer</title><meta name="description" content="I am a UI / UX designer. Studying Human-Computer Interaction at UMD."/><link rel="icon" href="/favicon.ico" type="image/x-icon" sizes="192x192"/><script src="/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body class="__variable_0771d4 __variable_4614e9 __variable_50eb80 antialiased relative"><header class="fixed l-0 t-0 w-full flex justify-center z-50 text-white backdrop-blur-md" style="mask-image:linear-gradient(to bottom, rgb(0 0 0 / 100%), rgb(0 0 0 / 100%) 80%, transparent)"><div class="flex px-4 sm:max-[1450px]:px-20 min-[1450px]:px-0 w-full min-[1450px]:w-7xl items-center text-sm sm:text-xl gap-4 sm:gap-7 h-24 my-0.5"><a href="/"><div><span class="text-[2.5rem] select-none font-picasso">ang</span></div></a><div class="grow"></div><a href="/about"><div><span class="hover:underline hover:underline-offset-4 font-serif">about me.</span></div></a><a target="_blank" rel="noopener noreferrer" href="https://drive.google.com/file/d/17-CJW2dArsCYxxthyIYxR-XOy4KzTuFk/view"><span class="hover:underline hover:underline-offset-4 font-serif">résumé.</span></a></div></header><div class="flex flex-col items-center pt-24 font-sans"><main class="relative flex flex-col w-full min-h-[70vh] items-center justify-center"><div class="pt-7 pb-7"><img alt="logo" width="30" height="30" decoding="async" data-nimg="1" style="color:transparent" src="/icons/logo/Unity.png"/></div><span class="pb-4 text-xl font-medium">Augmented Reality</span><span class="pb-7 text-5xl font-semibold flex gap-5 items-baseline">Pat Pet</span><div class="relative flex flex-col items-center h-[440px] w-full"><div class="relative h-full w-auto"><img aria-hidden="true" alt="Wireframe" loading="lazy" width="1419" height="2796" decoding="async" data-nimg="1" class="relative w-auto h-full z-30" style="color:transparent" src="/_next/static/media/iPhoneFrame.416f28af.png"/><video autoPlay="" muted="" loop="" playsInline="" class="absolute left-[19px] h-101 top-[18px] rounded-2xl z-0"><source src="/media/project/gesture-recognition-pet/10secVideo.mp4" type="video/mp4"/>Your browser does not support the video tag.</video></div></div><div class="flex w-full p-20 min-h-[450px] -mt-20 items-center justify-center" style="background-color:#3382C4"><span class="text-white text-center text-[36px] sm:text-[40px] leading-normal tracking-[.01em] whitespace-pre-line max-w-5xl font-medium">Bring joy and connection to your world with an AR pet that learns, grows, and plays by your side!</span></div></main><div class="flex w-full text-white justify-center"><div class="flex grow flex-col max-w-7xl gap-y-8 sm:gap-y-20 py-20 sm:p-20"><div class="grid grid-cols-1 sm:grid-cols-2 gap-4 sm:gap-8"><div class="flex flex-col p-7 gap-y-3 "><h1 class="text-[32px] sm:text-[40px] font-medium ">Project Overview</h1><p class="text-base sm:text-xl ">Pets offer companionship and emotional support, but owning a real pet isn&#x27;t always feasible. So we decided to make an Augmented Reality (AR) pet app that can interact with the user, and user can train and have fun with their AR pet. Users can interact with the pets through intuitive gestures or a user-friendly interface, such as training and nurturing their virtual pets.<br/><br/>While our initial focus is on interactive and engaging AR pets, we acknowledge the potential of emotional recognition technology to further personalize the user experience.</p></div><div class="flex flex-col p-7 gap-y-3 sm:justify-self-end"><div class="flex gap-x-5 py-3 items-start"><div class="self-start"><img aria-hidden="true" alt="icon" loading="lazy" width="48" height="48" decoding="async" data-nimg="1" class="min-w-12" style="color:transparent" src="/icons/LegoSmiley.svg"/></div><div class="grow flex flex-col gap-y-2"><h2 class="text-[28px] sm:text-[32px] font-medium ">Role</h2><p class="text-base sm:text-xl ">UIUX Designer &amp; Developer</p></div></div><div class="flex gap-x-5 py-3 items-start"><div class="self-start"><img aria-hidden="true" alt="icon" loading="lazy" width="48" height="48" decoding="async" data-nimg="1" class="min-w-12" style="color:transparent" src="/icons/Wrench.svg"/></div><div class="grow flex flex-col gap-y-2"><h2 class="text-[28px] sm:text-[32px] font-medium ">Tool</h2><p class="text-base sm:text-xl ">Figma, Unity, C#, Blender</p></div></div><div class="flex gap-x-5 py-3 items-start"><div class="self-start"><img aria-hidden="true" alt="icon" loading="lazy" width="48" height="48" decoding="async" data-nimg="1" class="min-w-12" style="color:transparent" src="/icons/Eyes.svg"/></div><div class="grow flex flex-col gap-y-2"><h2 class="text-[28px] sm:text-[32px] font-medium ">Project Size</h2><p class="text-base sm:text-xl ">2 People AR Class Project</p></div></div></div></div><div class="flex flex-col gap-y-5 items-start px-4 sm:px-0"><span class="text-8xl font-medium">01</span><span class="text-[36px] sm:text-[40px] font-medium">Why, Who, What?</span></div><div class="grid grid-cols-1 sm:grid-cols-3"><div class="flex flex-col p-7 gap-y-3 "><h2 class="text-[28px] sm:text-[32px] font-medium ">Why</h2><h3 class="text-[24px] sm:text-[28px] font-medium ">Emotional Support</h3><p class="text-base sm:text-xl ">Many people, like us, love animals and value the emotional support and companionship they provide but are unable to own a real pet due to restrictions or circumstances.</p></div><div class="flex flex-col p-7 gap-y-3 "><h2 class="text-[28px] sm:text-[32px] font-medium ">Who</h2><h3 class="text-[24px] sm:text-[28px] font-medium ">Pet Lover but...</h3><p class="text-base sm:text-xl ">Our target users are individuals who face challenges in owning a real pet due to various restrictions, including pet-restricted housing or financial constraints that make pet ownership impractical.</p></div><div class="flex flex-col p-7 gap-y-3 "><h2 class="text-[28px] sm:text-[32px] font-medium ">What</h2><h3 class="text-[24px] sm:text-[28px] font-medium ">Emotional Support</h3><p class="text-base sm:text-xl ">An AR-based platform that provides users with an interactive virtual pet. It helps users combat loneliness, offers fun and engaging activities, and creates the joy of keeping a pet.</p></div></div><div class="flex flex-col p-7 gap-y-3 "><h2 class="text-[28px] sm:text-[32px] font-medium ">User Persona</h2><div class="relative min-h-20 w-full"><img aria-hidden="true" alt="User Persona Image" loading="lazy" width="4256" height="2518" decoding="async" data-nimg="1" class="w-full h-auto" style="color:transparent" src="/_next/static/media/UserPersona.df1d6234.png"/></div></div><div class="flex flex-col p-7 gap-y-3 "><h2 class="text-[28px] sm:text-[32px] font-medium ">User Journey</h2><div class="relative min-h-20 w-full"><img aria-hidden="true" alt="User Journey Image" loading="lazy" width="4256" height="3365" decoding="async" data-nimg="1" class="w-full h-auto" style="color:transparent" src="/_next/static/media/UserJourney.f8247249.png"/></div></div><div class="grid grid-cols-1 sm:grid-cols-2 gap-4 sm:gap-8"><div class="flex flex-col p-7 gap-y-3 "><h2 class="text-[28px] sm:text-[32px] font-medium ">User Story</h2><p class="text-base sm:text-xl ">The user downloads the app, completes a simple onboarding process, and select a pet in app, the user sees the chosen virtual pet appear in their space through their phone.<br/><br/>The pet responds to real-world objects, like playing fetch with a tennis ball, and interacts with gestures, such as shaking hands virtually.<br/><br/>The user talks to the pet, which responds with supportive emotions and expressions, enhancing the sense of companionship.<br/><br/>The user walks the virtual pet in the real world, creating an immersive, engaging experience.</p></div><div class="flex flex-col p-7 gap-y-3 items-center justify-center"><img aria-hidden="true" alt="User Story image" loading="lazy" width="1069" height="1095" decoding="async" data-nimg="1" class="w-4/5 h-auto" style="color:transparent" src="/_next/static/media/UserStory.81bcb0c9.gif"/></div></div><div class="flex flex-col gap-y-5 items-start px-4 sm:px-0"><span class="text-8xl font-medium">02</span><span class="text-[36px] sm:text-[40px] font-medium">Core Functionalities</span></div><div class="grid grid-cols-1 sm:grid-cols-3"><div class="flex flex-col p-7 gap-y-3 items-center"><img aria-hidden="true" alt="pet image" loading="lazy" width="400" height="414" decoding="async" data-nimg="1" class="w-25 h-auto" style="color:transparent" src="/_next/static/media/Deer1.2b70f732.png"/><h2 class="text-[28px] sm:text-[32px] font-medium ">Virtual Doll</h2><p class="text-base sm:text-xl ">We aim to let users scan their own doll, and bring their emotion support object come to live.  Users would have more attachments to their familiar object.</p></div><div class="flex flex-col p-7 gap-y-3 items-center"><img aria-hidden="true" alt="pet image" loading="lazy" width="400" height="414" decoding="async" data-nimg="1" class="w-25 h-auto" style="color:transparent" src="/_next/static/media/Deer2.3f7a60a2.png"/><h2 class="text-[28px] sm:text-[32px] font-medium ">Mood Tracking</h2><p class="text-base sm:text-xl ">We worked on features such as recognition of users’ facial expressions and identify emotions such as happiness, sadness, anger, and stress.<br/><br/>Then, the AR pet can give some feedback and use generative AI to communicate with users.</p></div><div class="flex flex-col p-7 gap-y-3 items-center"><img aria-hidden="true" alt="pet image" loading="lazy" width="400" height="414" decoding="async" data-nimg="1" class="w-25 h-auto" style="color:transparent" src="/_next/static/media/Deer3.ad329914.png"/><h2 class="text-[28px] sm:text-[32px] font-medium ">Gesture Recognition</h2><p class="text-base sm:text-xl ">Users could engage with their AR doll in activities and create more intimacy with it.<br/><br/>Now we have gesture teaching and mood sharing. We would like to have more features like feeding and walking.</p></div></div><div class="flex flex-col gap-y-5 items-start px-4 sm:px-0"><span class="text-8xl font-medium">03</span><span class="text-[36px] sm:text-[40px] font-medium">Challenges, Breakthrough, &amp; Detour</span></div><div class="grid grid-cols-1 sm:grid-cols-2 gap-4 sm:gap-8"><div class="flex flex-col p-7 gap-y-3 "><div class="flex gap-x-5 py-3 items-start"><div class="self-start"><img aria-hidden="true" alt="icon" loading="lazy" width="48" height="48" decoding="async" data-nimg="1" class="min-w-12" style="color:transparent" src="/icons/ArrowRight.svg"/></div><div class="grow flex flex-col gap-y-2"><h3 class="text-[24px] sm:text-[28px] font-medium ">Unable to Use Unity Cloud</h3><p class="text-base sm:text-xl ">Due to obstacles encountered while collaborating on Unity Cloud, we transitioned our project code to GitHub. </p></div></div><div class="flex gap-x-5 py-3 items-start"><div class="self-start"><img aria-hidden="true" alt="icon" loading="lazy" width="48" height="48" decoding="async" data-nimg="1" class="min-w-12" style="color:transparent" src="/icons/ArrowRight.svg"/></div><div class="grow flex flex-col gap-y-2"><h3 class="text-[24px] sm:text-[28px] font-medium ">Hand Collision Detection</h3><p class="text-base sm:text-xl ">Achieving accurate and robust collision detection between hands and objects in interactive environments can be complex.</p></div></div></div><div class="flex flex-col p-7 gap-y-3 "><div class="flex gap-x-5 py-3 items-start"><div class="self-start"><img aria-hidden="true" alt="icon" loading="lazy" width="48" height="48" decoding="async" data-nimg="1" class="min-w-12" style="color:transparent" src="/icons/ArrowRight.svg"/></div><div class="grow flex flex-col gap-y-2"><h3 class="text-[24px] sm:text-[28px] font-medium ">Length of Fingers Varies</h3><p class="text-base sm:text-xl ">The length of a user&#x27;s fingers may have an impact on the effectiveness and accuracy of finger detection technologies.</p></div></div><div class="flex gap-x-5 py-3 items-start"><div class="self-start"><img aria-hidden="true" alt="icon" loading="lazy" width="48" height="48" decoding="async" data-nimg="1" class="min-w-12" style="color:transparent" src="/icons/ArrowRight.svg"/></div><div class="grow flex flex-col gap-y-2"><h3 class="text-[24px] sm:text-[28px] font-medium ">Plugin Confliction</h3><p class="text-base sm:text-xl ">The Emotion Recognition Plugin is causing conflicts with certain settings within our Unity project, resulting in unexpected behavior or errors.</p></div></div></div></div><div class="flex flex-col gap-y-5 items-start px-4 sm:px-0"><span class="text-8xl font-medium">04</span><span class="text-[36px] sm:text-[40px] font-medium">Design Strategy</span></div><div class="grid grid-cols-1 sm:grid-cols-2 gap-4 sm:gap-8"><div class="flex flex-col p-7 gap-y-3 "><h2 class="text-[28px] sm:text-[32px] font-medium ">MDA Framework</h2><p class="text-base sm:text-xl ">Guided by the principles of the MDA framework (Mechanics-Dynamics-Aesthetics), our app was designed to cultivate deep emotional connections.<br/><br/>Interactive elements go beyond passive engagement, fostering intimacy and trust between users and their virtual companions.<br/><br/>These dynamic interactions encourage users to express their emotions freely within a safe and supportive space, ultimately providing a valuable outlet for stress relief and emotional well-being.</p></div><div class="flex flex-col p-7 gap-y-3 items-center justify-center"><img aria-hidden="true" alt="Moodboard Image" loading="lazy" width="2021" height="1317" decoding="async" data-nimg="1" class="w-full h-auto" style="color:transparent" src="/_next/static/media/Moodboard.6b6a3ff7.png"/></div></div><div class="flex flex-col gap-y-5 items-start px-4 sm:px-0"><span class="text-8xl font-medium">05</span><span class="text-[36px] sm:text-[40px] font-medium">User Feedback &amp; Improving</span></div><img aria-hidden="true" alt="User Feedback Image" loading="lazy" width="3885" height="1669" decoding="async" data-nimg="1" class="w-4/5 h-auto self-center" style="color:transparent" src="/_next/static/media/UserFeedback.98b06a11.png"/><div class="grid grid-cols-1 sm:grid-cols-2 gap-4 sm:gap-8"><div class="flex flex-col p-7 gap-y-3 "><div class="flex gap-x-5 py-3 items-start"><div class="self-start"><img aria-hidden="true" alt="icon" loading="lazy" width="48" height="48" decoding="async" data-nimg="1" class="min-w-12" style="color:transparent" src="/icons/ArrowRight.svg"/></div><div class="grow flex flex-col gap-y-2"><h3 class="text-[24px] sm:text-[28px] font-medium ">Onboarding Process</h3><p class="text-base sm:text-xl ">Recognizing the unique challenges of navigating AR experiences, we incorporated Coach Marks into our onboarding process. These interactive tutorials address user confusion identified during testing, providing clear and concise instructions for interacting with AR elements.</p></div></div><div class="flex gap-x-5 py-3 items-start"><div class="self-start"><img aria-hidden="true" alt="icon" loading="lazy" width="48" height="48" decoding="async" data-nimg="1" class="min-w-12" style="color:transparent" src="/icons/ArrowRight.svg"/></div><div class="grow flex flex-col gap-y-2"><h3 class="text-[24px] sm:text-[28px] font-medium ">Gesture Instruction guide</h3><p class="text-base sm:text-xl ">To empower users to fully interact with their virtual pets, we implemented an in-app Gesture Instruction guide, which can clearly demonstrate the available gestures and provide exciting incentives for users to deepen their bond with their pet, unlocking new and engaging interaction possibilities.</p></div></div></div><div class="flex flex-col p-7 gap-y-3 "><div class="flex gap-x-5 py-3 items-start"><div class="self-start"><img aria-hidden="true" alt="icon" loading="lazy" width="48" height="48" decoding="async" data-nimg="1" class="min-w-12" style="color:transparent" src="/icons/ArrowRight.svg"/></div><div class="grow flex flex-col gap-y-2"><h3 class="text-[24px] sm:text-[28px] font-medium ">Add Progress Bar</h3><p class="text-base sm:text-xl ">A visually engaging Progress Bar has been implemented to incentivize consistent interaction with the virtual pet. This dynamic indicator visually represents the growing bond between the user and their pet, providing clear and motivating feedback.</p></div></div><div class="flex gap-x-5 py-3 items-start"><div class="self-start"><img aria-hidden="true" alt="icon" loading="lazy" width="48" height="48" decoding="async" data-nimg="1" class="min-w-12" style="color:transparent" src="/icons/ArrowRight.svg"/></div><div class="grow flex flex-col gap-y-2"><h3 class="text-[24px] sm:text-[28px] font-medium ">Emotion Diary</h3><p class="text-base sm:text-xl ">To enhance self-reflection and emotional awareness, we&#x27;ve integrated an Emotion Diary feature. Users can record their daily emotions, and the app will provide personalized suggestions based on their entries.</p></div></div></div></div><div class="flex flex-col gap-y-5 items-start px-4 sm:px-0"><span class="text-8xl font-medium">06</span><span class="text-[36px] sm:text-[40px] font-medium">Prototype</span><span class="text-base sm:text-xl">The prototype after user testing.</span></div></div></div><div class="flex flex-col p-7 gap-y-3 relative h-165"><div class="self-center relative h-151"><img aria-hidden="true" alt="Wireframe" loading="lazy" width="1419" height="2796" decoding="async" data-nimg="1" class="relative w-full h-full z-30" style="color:transparent" src="/_next/static/media/iPhoneFrame.416f28af.png"/><video autoPlay="" muted="" loop="" playsInline="" class="absolute left-[25px] h-139 top-[24px] rounded-3xl z-0"><source src="/media/project/gesture-recognition-pet/Video1.mp4" type="video/mp4"/>Your browser does not support the video tag.</video></div></div></div><footer class="border-t-[1px] border-solid border-zinc-500 flex flex-wrap gap-x-64 gap-y-16 items-center justify-center font-serif py-24 text-white bg-dark-bg"><div><a href="/"><div><span class="text-[2.5rem] select-none font-picasso">ang</span></div></a><div class="flex gap-x-4 pt-6 items-center"><a href="mailto:angela101475@gmail.com"><div><img alt="Goal Icon" loading="lazy" width="28" height="28" decoding="async" data-nimg="1" style="color:transparent" src="/icons/Envelope.svg"/></div></a><a target="_blank" rel="noopener noreferrer" href="https://github.com/AngelaMei"><img alt="Goal Icon" loading="lazy" width="28" height="28" decoding="async" data-nimg="1" style="color:transparent" src="/icons/GithubLogo.svg"/></a><a target="_blank" rel="noopener noreferrer" href="https://www.linkedin.com/in/angela-mei"><img alt="Goal Icon" loading="lazy" width="28" height="28" decoding="async" data-nimg="1" style="color:transparent" src="/icons/LinkedinLogo.svg"/></a></div></div><div class="grid grid-flow-row sm:grid-rows-[repeat(4,_auto)] sm:grid-flow-col gap-y-3 gap-x-20 auto-cols-max text-md sm:text-xl"><span class="text-xl sm:text-3xl font-medium py-2">site map.</span><a class="hover:underline hover:underline-offset-4" href="/"><div>home.</div></a><a class="hover:underline hover:underline-offset-4" href="/about"><div>about me.</div></a><a target="_blank" rel="noopener noreferrer" href="https://drive.google.com/file/d/17-CJW2dArsCYxxthyIYxR-XOy4KzTuFk/view"><span class="hover:underline hover:underline-offset-4 font-serif">résumé.</span></a><span class="sm:row-start-1 sm:col-span-2 text-xl sm:text-3xl font-medium py-2">selected works.</span><a class="hover:underline hover:underline-offset-4" href="/project/guide-app"><div>Guide App</div></a><a class="hover:underline hover:underline-offset-4" href="/project/coin-toss"><div>Coin Toss</div></a><a class="hover:underline hover:underline-offset-4" href="/project/gesture-recognition-pet"><div>Pat Pet</div></a><a class="hover:underline hover:underline-offset-4" href="/project/dairy-subscription-service"><div>Milky Way</div></a><a class="hover:underline hover:underline-offset-4" href="/project/student-social-life"><div>Student Social Life</div></a></div></footer><script src="/_next/static/chunks/webpack-004d1fe77d25eedc.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[3306,[\"565\",\"static/chunks/565-826789f130585a74.js\",\"295\",\"static/chunks/295-0f87b6b3c04a55eb.js\",\"177\",\"static/chunks/app/layout-1d05ed19c4855c67.js\"],\"default\"]\n3:I[3101,[\"565\",\"static/chunks/565-826789f130585a74.js\",\"295\",\"static/chunks/295-0f87b6b3c04a55eb.js\",\"177\",\"static/chunks/app/layout-1d05ed19c4855c67.js\"],\"DarkModeContextProvider\"]\n4:I[8715,[\"565\",\"static/chunks/565-826789f130585a74.js\",\"295\",\"static/chunks/295-0f87b6b3c04a55eb.js\",\"177\",\"static/chunks/app/layout-1d05ed19c4855c67.js\"],\"default\"]\n5:I[5244,[],\"\"]\n6:I[3866,[],\"\"]\n7:I[4370,[\"565\",\"static/chunks/565-826789f130585a74.js\",\"295\",\"static/chunks/295-0f87b6b3c04a55eb.js\",\"177\",\"static/chunks/app/layout-1d05ed19c4855c67.js\"],\"default\"]\n8:I[766,[\"565\",\"static/chunks/565-826789f130585a74.js\",\"295\",\"static/chunks/295-0f87b6b3c04a55eb.js\",\"177\",\"static/chunks/app/layout-1d05ed19c4855c67.js\"],\"GoogleAnalytics\"]\n9:I[3539,[\"565\",\"static/chunks/565-826789f130585a74.js\",\"986\",\"static/chunks/app/project/gesture-recognition-pet/page-82abab72787272c6.js\"],\"default\"]\na:I[8069,[\"565\",\"static/chunks/565-826789f130585a74.js\",\"986\",\"static/chunks/app/project/gesture-recognition-pet/page-82abab72787272c6.js\"],\"ImageWrapper\"]\nb:I[7970,[\"565\",\"static/chunks/565-826789f130585a74.js\",\"986\",\"static/chunks/app/project/gesture-recognition-pet/page-82abab72787272c6.js\"],\"Image\"]\nc:I[8069,[\"565\",\"static/chunks/565-826789f130585a74.js\",\"986\",\"static/chunks/app/project/gesture-recognition-pet/page-82abab72787272c6.js\"],\"PageContentContainer\"]\nd:I[8069,[\"565\",\"static/chunks/565-826789f130585a74.js\",\"986\",\"static/chunks/app/project/gesture-recognition-pet/page-82abab72787272c6.js\"],\"TwoColumn\"]\ne:I[8069,[\"565\",\"static/chunks/565-826789f130585a74.js\",\"986\",\"static/chunks/app/project/gesture-recognition-pet/page-82abab72787272c6.js\"],\"PaddedFlexBox\"]\nf:I[8069,[\"565\",\"static/chunks/565-826789f130585a74.js\",\"986\",\"static/chunks/app/project/gesture-recognition-pet/page-82abab72787272c6.js\"],\"Heading1\"]\n10:I[8069,[\"565\",\"static/chunks/565-826789f130585a74.js"])</script><script>self.__next_f.push([1,"\",\"986\",\"static/chunks/app/project/gesture-recognition-pet/page-82abab72787272c6.js\"],\"BaseText\"]\n11:I[8069,[\"565\",\"static/chunks/565-826789f130585a74.js\",\"986\",\"static/chunks/app/project/gesture-recognition-pet/page-82abab72787272c6.js\"],\"IconBullet\"]\n12:I[8069,[\"565\",\"static/chunks/565-826789f130585a74.js\",\"986\",\"static/chunks/app/project/gesture-recognition-pet/page-82abab72787272c6.js\"],\"Heading2\"]\n13:I[8069,[\"565\",\"static/chunks/565-826789f130585a74.js\",\"986\",\"static/chunks/app/project/gesture-recognition-pet/page-82abab72787272c6.js\"],\"SectionTitle\"]\n14:I[8069,[\"565\",\"static/chunks/565-826789f130585a74.js\",\"986\",\"static/chunks/app/project/gesture-recognition-pet/page-82abab72787272c6.js\"],\"ThreeColumn\"]\n15:I[8069,[\"565\",\"static/chunks/565-826789f130585a74.js\",\"986\",\"static/chunks/app/project/gesture-recognition-pet/page-82abab72787272c6.js\"],\"Heading3\"]\n16:I[6213,[],\"OutletBoundary\"]\n18:I[6213,[],\"MetadataBoundary\"]\n1a:I[6213,[],\"ViewportBoundary\"]\n1c:I[4835,[],\"\"]\n:HL[\"/_next/static/media/29a6e977ce941007-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/media/575bcb56b500cc9b-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/media/a5c349ac2ad38ba2-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/css/5e26cd74581c4c3d.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"5VZZ06qa6hck3SF9koH1t\",\"p\":\"\",\"c\":[\"\",\"project\",\"gesture-recognition-pet\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"project\",{\"children\":[\"gesture-recognition-pet\",{\"children\":[\"__PAGE__\",{}]}]}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/5e26cd74581c4c3d.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"children\":[[\"$\",\"body\",null,{\"className\":\"__variable_0771d4 __variable_4614e9 __variable_50eb80 antialiased relative\",\"children\":[\"$\",\"$L2\",null,{\"children\":[\"$\",\"$L3\",null,{\"value\":true,\"children\":[[\"$\",\"$L4\",null,{}],[\"$\",\"$L5\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L6\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[],[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}],[\"$\",\"$L7\",null,{}]]}]}]}],[\"$\",\"$L8\",null,{\"gaId\":\"G-7GRVFVX2JL\"}]]}]]}],{\"children\":[\"project\",[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L5\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"project\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L6\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[\"gesture-recognition-pet\",[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L5\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"project\",\"children\",\"gesture-recognition-pet\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L6\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[[\"$\",\"div\",null,{\"className\":\"flex flex-col items-center pt-24 font-sans\",\"children\":[[\"$\",\"$L9\",null,{\"id\":\"gesture-recognition-pet\",\"pageUrl\":\"/project/gesture-recognition-pet\",\"coverImage\":{\"src\":\"/_next/static/media/Cover_Patpet.d5b5959b.png\",\"height\":442,\"width\":653,\"blurDataURL\":\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAFCAMAAABPT11nAAAAM1BMVEVrV0ZBPDa4qJdTTUVqYFkwLCMSEQ7GtaMBAQEJCAevoJIgHRebj4F2cWmNcmfAm4h6WU28sXFrAAAACHRSTlP8////////+3pjkS4AAAAJcEhZcwAACxMAAAsTAQCanBgAAAAuSURBVHicHcZHDgAgDAOwdJKy//9aJHwyyJQ1taEqxbsqRoSZewfJirv9J+XgARdtARFSgCh5AAAAAElFTkSuQmCC\",\"blurWidth\":8,\"blurHeight\":5},\"type\":\"Augmented Reality\",\"name\":\"Pat Pet\",\"role\":\"Product Designer \u0026 Developer\",\"description\":\"Developed an Augmented Reality (AR) pet app with intuitive gesture interactions, allowing users to train and play with their virtual companions.\",\"iconUrl\":\"/icons/logo/Unity.png\",\"bannerText\":\"Bring joy and connection to your world with an AR pet that learns, grows, and plays by your side!\",\"themeColor\":\"#3382C4\",\"completed\":true,\"heroCover\":[\"$\",\"$La\",null,{\"className\":\"relative\",\"children\":[[\"$\",\"$Lb\",null,{\"className\":\"relative w-auto h-full z-30\",\"aria-hidden\":true,\"src\":{\"src\":\"/_next/static/media/iPhoneFrame.416f28af.png\",\"height\":2796,\"width\":1419,\"blurDataURL\":\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAQAAAAICAMAAADp7a43AAAABlBMVEUkJCRMaXHI9qqiAAAAAnRSTlMjAMg6ulkAAAAJcEhZcwAACxMAAAsTAQCanBgAAAASSURBVHicY2AAA0ZGfAQDAwMAARgADXnZu4MAAAAASUVORK5CYII=\",\"blurWidth\":4,\"blurHeight\":8},\"alt\":\"Wireframe\"}],[\"$\",\"video\",null,{\"autoPlay\":true,\"muted\":true,\"loop\":true,\"playsInline\":true,\"className\":\"absolute left-[19px] h-101 top-[18px] rounded-2xl z-0\",\"children\":[[\"$\",\"source\",null,{\"src\":\"/media/project/gesture-recognition-pet/10secVideo.mp4\",\"type\":\"video/mp4\"}],\"Your browser does not support the video tag.\"]}]]}]}],[\"$\",\"$Lc\",null,{\"children\":[[\"$\",\"$Ld\",null,{\"children\":[[\"$\",\"$Le\",null,{\"children\":[[\"$\",\"$Lf\",null,{\"children\":\"Project Overview\"}],[\"$\",\"$L10\",null,{\"children\":[\"Pets offer companionship and emotional support, but owning a real pet isn't always feasible. So we decided to make an Augmented Reality (AR) pet app that can interact with the user, and user can train and have fun with their AR pet. Users can interact with the pets through intuitive gestures or a user-friendly interface, such as training and nurturing their virtual pets.\",[\"$\",\"br\",null,{}],[\"$\",\"br\",null,{}],\"While our initial focus is on interactive and engaging AR pets, we acknowledge the potential of emotional recognition technology to further personalize the user experience.\"]}]]}],[\"$\",\"$Le\",null,{\"className\":\"sm:justify-self-end\",\"children\":[[\"$\",\"$L11\",null,{\"iconUrl\":\"/icons/LegoSmiley.svg\",\"children\":[[\"$\",\"$L12\",null,{\"children\":\"Role\"}],[\"$\",\"$L10\",null,{\"children\":\"UIUX Designer \u0026 Developer\"}]]}],[\"$\",\"$L11\",null,{\"iconUrl\":\"/icons/Wrench.svg\",\"children\":[[\"$\",\"$L12\",null,{\"children\":\"Tool\"}],[\"$\",\"$L10\",null,{\"children\":\"Figma, Unity, C#, Blender\"}]]}],[\"$\",\"$L11\",null,{\"iconUrl\":\"/icons/Eyes.svg\",\"children\":[[\"$\",\"$L12\",null,{\"children\":\"Project Size\"}],[\"$\",\"$L10\",null,{\"children\":\"2 People AR Class Project\"}]]}]]}]]}],[\"$\",\"$L13\",null,{\"id\":\"01\",\"title\":\"Why, Who, What?\"}],[\"$\",\"$L14\",null,{\"children\":[[\"$\",\"$Le\",null,{\"children\":[[\"$\",\"$L12\",null,{\"children\":\"Why\"}],[\"$\",\"$L15\",null,{\"children\":\"Emotional Support\"}],[\"$\",\"$L10\",null,{\"children\":\"Many people, like us, love animals and value the emotional support and companionship they provide but are unable to own a real pet due to restrictions or circumstances.\"}]]}],[\"$\",\"$Le\",null,{\"children\":[[\"$\",\"$L12\",null,{\"children\":\"Who\"}],[\"$\",\"$L15\",null,{\"children\":\"Pet Lover but...\"}],[\"$\",\"$L10\",null,{\"children\":\"Our target users are individuals who face challenges in owning a real pet due to various restrictions, including pet-restricted housing or financial constraints that make pet ownership impractical.\"}]]}],[\"$\",\"$Le\",null,{\"children\":[[\"$\",\"$L12\",null,{\"children\":\"What\"}],[\"$\",\"$L15\",null,{\"children\":\"Emotional Support\"}],[\"$\",\"$L10\",null,{\"children\":\"An AR-based platform that provides users with an interactive virtual pet. It helps users combat loneliness, offers fun and engaging activities, and creates the joy of keeping a pet.\"}]]}]]}],[\"$\",\"$Le\",null,{\"children\":[[\"$\",\"$L12\",null,{\"children\":\"User Persona\"}],[\"$\",\"div\",null,{\"className\":\"relative min-h-20 w-full\",\"children\":[\"$\",\"$Lb\",null,{\"className\":\"w-full h-auto\",\"aria-hidden\":true,\"src\":{\"src\":\"/_next/static/media/UserPersona.df1d6234.png\",\"height\":2518,\"width\":4256,\"blurDataURL\":\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAFCAMAAABPT11nAAAAFVBMVEXw8PDo6Of09PTw8PD5+fbo6uv18uRkXAWxAAAAAnRSTlPx8bGO304AAAAJcEhZcwAALEsAACxLAaU9lqkAAAAlSURBVHicJcKBDcAwAMIwmkD/P7maJjuCn2ydSlbmJLe1SE7+DwtLAG/IeChwAAAAAElFTkSuQmCC\",\"blurWidth\":8,\"blurHeight\":5},\"alt\":\"User Persona Image\"}]}]]}],[\"$\",\"$Le\",null,{\"children\":[[\"$\",\"$L12\",null,{\"children\":\"User Journey\"}],[\"$\",\"div\",null,{\"className\":\"relative min-h-20 w-full\",\"children\":[\"$\",\"$Lb\",null,{\"className\":\"w-full h-auto\",\"aria-hidden\":true,\"src\":{\"src\":\"/_next/static/media/UserJourney.f8247249.png\",\"height\":3365,\"width\":4256,\"blurDataURL\":\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAGCAMAAADJ2y/JAAAAHlBMVEWcssCjt8Oqvcju7u/09fbT3uLk5+jD1uKbyt+u1t9+JmSzAAAAA3RSTlP+/v6VFoksAAAACXBIWXMAACxLAAAsSwGlPZapAAAALUlEQVR4nBXIwREAIAgDwcMkKP037PDcJUmrJWbeuzdB1oawbcmmTkEB65b9ARdtAL2kunw4AAAAAElFTkSuQmCC\",\"blurWidth\":8,\"blurHeight\":6},\"alt\":\"User Journey Image\"}]}]]}],[\"$\",\"$Ld\",null,{\"children\":[[\"$\",\"$Le\",null,{\"children\":[[\"$\",\"$L12\",null,{\"children\":\"User Story\"}],[\"$\",\"$L10\",null,{\"children\":[\"The user downloads the app, completes a simple onboarding process, and select a pet in app, the user sees the chosen virtual pet appear in their space through their phone.\",[\"$\",\"br\",null,{}],[\"$\",\"br\",null,{}],\"The pet responds to real-world objects, like playing fetch with a tennis ball, and interacts with gestures, such as shaking hands virtually.\",[\"$\",\"br\",null,{}],[\"$\",\"br\",null,{}],\"The user talks to the pet, which responds with supportive emotions and expressions, enhancing the sense of companionship.\",[\"$\",\"br\",null,{}],[\"$\",\"br\",null,{}],\"The user walks the virtual pet in the real world, creating an immersive, engaging experience.\"]}]]}],[\"$\",\"$Le\",null,{\"className\":\"items-center justify-center\",\"children\":[\"$\",\"$Lb\",null,{\"className\":\"w-4/5 h-auto\",\"aria-hidden\":true,\"src\":{\"src\":\"/_next/static/media/UserStory.81bcb0c9.gif\",\"height\":1095,\"width\":1069,\"blurWidth\":0,\"blurHeight\":0},\"alt\":\"User Story image\"}]}]]}],[\"$\",\"$L13\",null,{\"id\":\"02\",\"title\":\"Core Functionalities\"}],[\"$\",\"$L14\",null,{\"children\":[[\"$\",\"$Le\",null,{\"className\":\"items-center\",\"children\":[[\"$\",\"$Lb\",null,{\"className\":\"w-25 h-auto\",\"aria-hidden\":true,\"src\":{\"src\":\"/_next/static/media/Deer1.2b70f732.png\",\"height\":414,\"width\":400,\"blurDataURL\":\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAICAMAAADz0U65AAAAdVBMVEVMaXGTfnF0XVJrXUL5vZuHa1ymhGeZfmutj4vAg2CeXDfPrIXMvKShjX/vyqjtt5eldWr////iooDtwKeql4351cT4ypyCaV+YdWXRqoesg2W/qJHKnXiuYk3iv7HMmYicgHC6bFr637j0yqvr18Kha1jBZ08oF9smAAAAInRSTlMAcM8J48jZSBnr44L1/IRW/BH5cjZXuJn9/v04wsIkS66SKjrlgQAAAAlwSFlzAAAsSwAALEsBpT2WqQAAAEJJREFUeJwFwQUCgCAAALEDSbs7Mf7/RDdaATgRYXUFVkY0esDJ80DVpl/Nd9GpEKZ52yF/0mxcgOIuX+8AEh9b+AFsWgNEo5fjhQAAAABJRU5ErkJggg==\",\"blurWidth\":8,\"blurHeight\":8},\"alt\":\"pet image\"}],[\"$\",\"$L12\",null,{\"children\":\"Virtual Doll\"}],[\"$\",\"$L10\",null,{\"children\":\"We aim to let users scan their own doll, and bring their emotion support object come to live.  Users would have more attachments to their familiar object.\"}]]}],[\"$\",\"$Le\",null,{\"className\":\"items-center\",\"children\":[[\"$\",\"$Lb\",null,{\"className\":\"w-25 h-auto\",\"aria-hidden\":true,\"src\":{\"src\":\"/_next/static/media/Deer2.3f7a60a2.png\",\"height\":414,\"width\":400,\"blurDataURL\":\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAICAMAAADz0U65AAAAb1BMVEVMaXG4j3GKcmWlj4Lbupbbr5rarYO1qp15YFP19fWReG26bl2CSyWdXDTEkGO9hWLkxKKJdGj0y6m2p5i/mX/81K+9l3X4zqH3y6X9vaKudV39xKyngW5pVEjApYytaU7Oln6GX1FyVEH5t5DAY0gZ5urmAAAAHnRSTlMA2K5MKh3tGMsQJJsvtLTS/frW+Vhg/fSjlZ6ryc1B+VAHAAAACXBIWXMAACxLAAAsSwGlPZapAAAAQklEQVR4nAXBBQKAIAAAsUMa7E7M/7/RjZB5sFnAOgnysCzCaeX2yPaayYgv4udUj8/qYUhdc/eAbq+zsgCqLHL4AWfGAxo86u9HAAAAAElFTkSuQmCC\",\"blurWidth\":8,\"blurHeight\":8},\"alt\":\"pet image\"}],[\"$\",\"$L12\",null,{\"children\":\"Mood Tracking\"}],[\"$\",\"$L10\",null,{\"children\":[\"We worked on features such as recognition of users’ facial expressions and identify emotions such as happiness, sadness, anger, and stress.\",[\"$\",\"br\",null,{}],[\"$\",\"br\",null,{}],\"Then, the AR pet can give some feedback and use generative AI to communicate with users.\"]}]]}],[\"$\",\"$Le\",null,{\"className\":\"items-center\",\"children\":[[\"$\",\"$Lb\",null,{\"className\":\"w-25 h-auto\",\"aria-hidden\":true,\"src\":{\"src\":\"/_next/static/media/Deer3.ad329914.png\",\"height\":414,\"width\":400,\"blurDataURL\":\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAICAMAAADz0U65AAAAdVBMVEVMaXG1aVV2X1SnhXHzz6b///9yV0n128qPfne/qJGDVjHEmXufYDj1xaPEkWTCg2LKon6/sZ6TgXL806ySeWz/xKf1w5/YsqXXsIm5k3L/xqzhr4S8lX6Cal7Agmx4VUnRtZmpgmWukX/SupuHaFH1tI+/ZUvY6lRdAAAAH3RSTlMAs8HL8gbPHik8PiPL4snh/fj4Y5ePsxTh37rnY5yPLZr2ogAAAAlwSFlzAAAsSwAALEsBpT2WqQAAAEFJREFUeJwFwYUBwCAAwLDiMHd3+//EJfjGgFk93gYI1tMq2TupNqZ30PP4CVx36+IRDuqrrPYFcOlx5jFAyJIIfnBsAzrCT+YQAAAAAElFTkSuQmCC\",\"blurWidth\":8,\"blurHeight\":8},\"alt\":\"pet image\"}],[\"$\",\"$L12\",null,{\"children\":\"Gesture Recognition\"}],[\"$\",\"$L10\",null,{\"children\":[\"Users could engage with their AR doll in activities and create more intimacy with it.\",[\"$\",\"br\",null,{}],[\"$\",\"br\",null,{}],\"Now we have gesture teaching and mood sharing. We would like to have more features like feeding and walking.\"]}]]}]]}],[\"$\",\"$L13\",null,{\"id\":\"03\",\"title\":\"Challenges, Breakthrough, \u0026 Detour\"}],[\"$\",\"$Ld\",null,{\"children\":[[\"$\",\"$Le\",null,{\"children\":[[\"$\",\"$L11\",null,{\"iconUrl\":\"/icons/ArrowRight.svg\",\"children\":[[\"$\",\"$L15\",null,{\"children\":\"Unable to Use Unity Cloud\"}],[\"$\",\"$L10\",null,{\"children\":\"Due to obstacles encountered while collaborating on Unity Cloud, we transitioned our project code to GitHub. \"}]]}],[\"$\",\"$L11\",null,{\"iconUrl\":\"/icons/ArrowRight.svg\",\"children\":[[\"$\",\"$L15\",null,{\"children\":\"Hand Collision Detection\"}],[\"$\",\"$L10\",null,{\"children\":\"Achieving accurate and robust collision detection between hands and objects in interactive environments can be complex.\"}]]}]]}],[\"$\",\"$Le\",null,{\"children\":[[\"$\",\"$L11\",null,{\"iconUrl\":\"/icons/ArrowRight.svg\",\"children\":[[\"$\",\"$L15\",null,{\"children\":\"Length of Fingers Varies\"}],[\"$\",\"$L10\",null,{\"children\":\"The length of a user's fingers may have an impact on the effectiveness and accuracy of finger detection technologies.\"}]]}],[\"$\",\"$L11\",null,{\"iconUrl\":\"/icons/ArrowRight.svg\",\"children\":[[\"$\",\"$L15\",null,{\"children\":\"Plugin Confliction\"}],[\"$\",\"$L10\",null,{\"children\":\"The Emotion Recognition Plugin is causing conflicts with certain settings within our Unity project, resulting in unexpected behavior or errors.\"}]]}]]}]]}],[\"$\",\"$L13\",null,{\"id\":\"04\",\"title\":\"Design Strategy\"}],[\"$\",\"$Ld\",null,{\"children\":[[\"$\",\"$Le\",null,{\"children\":[[\"$\",\"$L12\",null,{\"children\":\"MDA Framework\"}],[\"$\",\"$L10\",null,{\"children\":[\"Guided by the principles of the MDA framework (Mechanics-Dynamics-Aesthetics), our app was designed to cultivate deep emotional connections.\",[\"$\",\"br\",null,{}],[\"$\",\"br\",null,{}],\"Interactive elements go beyond passive engagement, fostering intimacy and trust between users and their virtual companions.\",[\"$\",\"br\",null,{}],[\"$\",\"br\",null,{}],\"These dynamic interactions encourage users to express their emotions freely within a safe and supportive space, ultimately providing a valuable outlet for stress relief and emotional well-being.\"]}]]}],[\"$\",\"$Le\",null,{\"className\":\"items-center justify-center\",\"children\":[\"$\",\"$Lb\",null,{\"className\":\"w-full h-auto\",\"aria-hidden\":true,\"src\":{\"src\":\"/_next/static/media/Moodboard.6b6a3ff7.png\",\"height\":1317,\"width\":2021,\"blurDataURL\":\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAFCAMAAABPT11nAAAAYFBMVEWwn4vV1dDrx7/y0LKe0O68hnK0yKzy2cPoxKO3qLbq2Mr51s6Zxt3w4sihkYDTx6+TusW8xb6mwNHoqp6RbE3OvL6Sv9b0uIH8yJnNpIWHTkdhsczXv4j58/bQn4HcfV/r32TvAAAADHRSTlP+/P79/v78/f7+/v0kTD9OAAAACXBIWXMAACxLAAAsSwGlPZapAAAANUlEQVR4nGNgZ+LiYeFkZWPgEOblERLgk2dgluAV4xHkZ2dgEOdg4JeRk2VgFJUU4ZOW4gYAK28CQl2MwhEAAAAASUVORK5CYII=\",\"blurWidth\":8,\"blurHeight\":5},\"alt\":\"Moodboard Image\"}]}]]}],[\"$\",\"$L13\",null,{\"id\":\"05\",\"title\":\"User Feedback \u0026 Improving\"}],[\"$\",\"$Lb\",null,{\"className\":\"w-4/5 h-auto self-center\",\"aria-hidden\":true,\"src\":{\"src\":\"/_next/static/media/UserFeedback.98b06a11.png\",\"height\":1669,\"width\":3885,\"blurDataURL\":\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAADCAMAAACZFr56AAAAKlBMVEXdxGjx1HHhx2rlyWpMaXHdv2Tox2DUvWbZwGj733H//7npzGD43XXky20u3dxNAAAADHRSTlO/eWZ2AIKNWj2LC8h1qhDOAAAACXBIWXMAACxLAAAsSwGlPZapAAAAI0lEQVR4nGNgZWZhY2RhZWLg4WTiYWTnZWTgZuNiYOZgYAAABsQAfvfU7LsAAAAASUVORK5CYII=\",\"blurWidth\":8,\"blurHeight\":3},\"alt\":\"User Feedback Image\"}],[\"$\",\"$Ld\",null,{\"children\":[[\"$\",\"$Le\",null,{\"children\":[[\"$\",\"$L11\",null,{\"iconUrl\":\"/icons/ArrowRight.svg\",\"children\":[[\"$\",\"$L15\",null,{\"children\":\"Onboarding Process\"}],[\"$\",\"$L10\",null,{\"children\":\"Recognizing the unique challenges of navigating AR experiences, we incorporated Coach Marks into our onboarding process. These interactive tutorials address user confusion identified during testing, providing clear and concise instructions for interacting with AR elements.\"}]]}],[\"$\",\"$L11\",null,{\"iconUrl\":\"/icons/ArrowRight.svg\",\"children\":[[\"$\",\"$L15\",null,{\"children\":\"Gesture Instruction guide\"}],[\"$\",\"$L10\",null,{\"children\":\"To empower users to fully interact with their virtual pets, we implemented an in-app Gesture Instruction guide, which can clearly demonstrate the available gestures and provide exciting incentives for users to deepen their bond with their pet, unlocking new and engaging interaction possibilities.\"}]]}]]}],[\"$\",\"$Le\",null,{\"children\":[[\"$\",\"$L11\",null,{\"iconUrl\":\"/icons/ArrowRight.svg\",\"children\":[[\"$\",\"$L15\",null,{\"children\":\"Add Progress Bar\"}],[\"$\",\"$L10\",null,{\"children\":\"A visually engaging Progress Bar has been implemented to incentivize consistent interaction with the virtual pet. This dynamic indicator visually represents the growing bond between the user and their pet, providing clear and motivating feedback.\"}]]}],[\"$\",\"$L11\",null,{\"iconUrl\":\"/icons/ArrowRight.svg\",\"children\":[[\"$\",\"$L15\",null,{\"children\":\"Emotion Diary\"}],[\"$\",\"$L10\",null,{\"children\":\"To enhance self-reflection and emotional awareness, we've integrated an Emotion Diary feature. Users can record their daily emotions, and the app will provide personalized suggestions based on their entries.\"}]]}]]}]]}],[\"$\",\"$L13\",null,{\"id\":\"06\",\"title\":\"Prototype\",\"subtitle\":\"The prototype after user testing.\"}]]}],[\"$\",\"$Le\",null,{\"className\":\"relative h-165\",\"children\":[\"$\",\"div\",null,{\"className\":\"self-center relative h-151\",\"children\":[[\"$\",\"$Lb\",null,{\"className\":\"relative w-full h-full z-30\",\"aria-hidden\":true,\"src\":\"$0:f:0:1:2:children:2:children:2:children:1:props:children:0:props:children:0:props:heroCover:props:children:0:props:src\",\"alt\":\"Wireframe\"}],[\"$\",\"video\",null,{\"autoPlay\":true,\"muted\":true,\"loop\":true,\"playsInline\":true,\"className\":\"absolute left-[25px] h-139 top-[24px] rounded-3xl z-0\",\"children\":[[\"$\",\"source\",null,{\"src\":\"/media/project/gesture-recognition-pet/Video1.mp4\",\"type\":\"video/mp4\"}],\"Your browser does not support the video tag.\"]}]]}]}]]}],null,[\"$\",\"$L16\",null,{\"children\":\"$L17\"}]]}],{},null,false]},null,false]},null,false]},null,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$1\",\"y5Dag1EfYDQ5MOLcKCnCT\",{\"children\":[[\"$\",\"$L18\",null,{\"children\":\"$L19\"}],[\"$\",\"$L1a\",null,{\"children\":\"$L1b\"}],[\"$\",\"meta\",null,{\"name\":\"next-size-adjust\",\"content\":\"\"}]]}]]}],false]],\"m\":\"$undefined\",\"G\":[\"$1c\",\"$undefined\"],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"1b:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\n19:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"1\",{\"children\":\"Mei Yu Chi | UI/UX Designer\"}],[\"$\",\"meta\",\"2\",{\"name\":\"description\",\"content\":\"I am a UI / UX designer. Studying Human-Computer Interaction at UMD.\"}],[\"$\",\"link\",\"3\",{\"rel\":\"icon\",\"href\":\"/favicon.ico\",\"type\":\"image/x-icon\",\"sizes\":\"192x192\"}]]\n"])</script><script>self.__next_f.push([1,"17:null\n"])</script></body></html>